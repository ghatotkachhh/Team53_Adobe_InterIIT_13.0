{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install qwen-vl-utils\n",
    "!pip install jsonformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoModelForCausalLM, AutoTokenizer, AutoProcessor, BitsAndBytesConfig, AutoModelForVision2Seq\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import os\n",
    "import gc\n",
    "from tqdm.notebook import tqdm_notebook as tqdm   \n",
    "import json\n",
    "import re\n",
    "from jsonformer import Jsonformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id =\"/kaggle/input/qwen7bfinetuned/qwen2-7b-instruct-artifact\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    " \n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(model_id, device_map=\"auto\",quantization_config=bnb_config)\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_prompt = \"\"\"\n",
    "TASK: You are given an AI Generated Image and you are supposed to find out which groups of problems are present in the particular image. You can select multiple groups from the provided context.\n",
    "Explain reasoning behind choosing the groups. \n",
    "\n",
    "Groups:-\n",
    "AI Defects: Floating parts, Noise on flat areas, Weird perspective, Blurred details, Ghosting/Repeats\n",
    "\n",
    "Biological Defects: Misaligned, Deformed, Fur errors, Unrealistic eyes, Asymmetry\n",
    "\n",
    "Overprocessing: Grid artifacts, Cinematic look, Over-sharpening, Dramatic lighting, Scale issues\n",
    "\n",
    "Reality Breaks: Non-manifold, Asymmetric, Proportion errors, Impossible joints, Jagged edges\n",
    "\n",
    "Scene Oddities: Metallic artifacts, Distorted reflections, Specular issues, Shadow inconsistencies, Glossy surfaces\n",
    "\n",
    "Texture Defects: Depth anomalies, Blurred edges, Aliasing, Texture bleeding, Fake depth, Synthetic look, Color breaks\n",
    "\n",
    "Remember: Do not bolden or number your headings, Just mention the heading and a newline between the heading and explanation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_defects = \"\"\"\n",
    "TASK: For the provided artifacts, Shortlist the artifacts which are applicable to the given image.\n",
    "Generate proper explanations for the artifacts shortlisted. EXPLAIN IN WHICH PART OF THE IMAGE THE ARTIFACT IS EXHIBITED.\n",
    "Omit the artifact if it is not applicable to the image. Explain strictly in context of the given image.\n",
    "\n",
    "artifacts:- \n",
    "Floating or disconnected components\n",
    "Artificial noise patterns in uniform surfaces\n",
    "Incorrect perspective rendering\n",
    "Spatial relationship errors\n",
    "Random noise patterns in detailed areas\n",
    "Loss of fine detail in complex structures\n",
    "Artificial enhancement artifacts\n",
    "Abruptly cut off objects\n",
    "Ghosting effects: Semi-transparent duplicates of elements\n",
    "Repeated Element Patterns\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reality_breaks = \"\"\"\n",
    "TASK: For the provided artifacts, Shortlist the artifacts which are applicable to the given image. \n",
    "Generate proper explanations for the artifacts shortlisted. EXPLAIN IN WHICH PART OF THE IMAGE THE ARTIFACT IS EXHIBITED.\n",
    "Omit the artifact if it is not applicable to the image. Explain strictly in context of the given image.\n",
    "\n",
    "artifacts:- \n",
    "Non-manifold geometries in rigid structures\n",
    "Asymmetric features in naturally symmetric objects\n",
    "Irregular proportions in mechanical components \n",
    "Inconsistent material properties\n",
    "Impossible mechanical connections\n",
    "Inconsistent scale of mechanical parts\n",
    "Physically impossible structural elements\n",
    "Jagged edges in curved structures\n",
    "Implausible aerodynamic structures\n",
    "Impossible mechanical joints\n",
    "Impossible foreshortening in animal bodies\n",
    "Discontinuous surfaces\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Surface_Depth_Edge_Problems = \"\"\"\n",
    "TASK: For the provided artifacts, Shortlist the artifacts which are applicable to the given image. \n",
    "Generate proper explanations for the artifacts shortlisted. EXPLAIN IN WHICH PART OF THE IMAGE THE ARTIFACT IS EXHIBITED.\n",
    "Omit the artifact if it is not applicable to the image. Explain strictly in context of the given image.\n",
    "\n",
    "artifacts:- \n",
    "Discontinuous surfaces\n",
    "Over-smoothing of natural textures \n",
    "Depth perception anomalies\n",
    "Blurred boundaries in fine details\n",
    "Aliasing along high-contrast edges\n",
    "Texture bleeding between adjacent regions\n",
    "Fake depth of field\n",
    "Glow or light bleed around object boundaries\n",
    "Artificial depth of field in object presentation\n",
    "Synthetic material appearance\n",
    "Color coherence breaks\n",
    "Inconsistent object boundaries\n",
    "Systematic color distribution anomalies\n",
    "Resolution inconsistencies within regions\n",
    "Texture repetition patterns\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Biological_issues = \"\"\"\n",
    "TASK: For the provided artifacts, Shortlist the artifacts which are applicable to the given image. \n",
    "Generate proper explanations for the artifacts shortlisted. EXPLAIN IN WHICH PART OF THE IMAGE THE ARTIFACT IS EXHIBITED.\n",
    "Omit the artifact if it is not applicable to the image. Explain strictly in context of the given image.\n",
    "\n",
    "artifacts:- \n",
    "Misaligned bilateral elements in animal faces \n",
    "Dental anomalies in mammals \n",
    "Anatomically incorrect paw structures\n",
    "Improper fur direction flows\n",
    "Unrealistic eye reflections\n",
    "Misshapen ears or appendages\n",
    "Anatomically impossible joint configurations\n",
    "Unnatural pose artifacts\n",
    "Biological asymmetry errors\n",
    "Incorrect Skin Tones\n",
    "Misaligned body panels\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scene_oddities = \"\"\"\n",
    "TASK: For the provided artifacts, Shortlist the artifacts which are applicable to the given image.\n",
    "Generate proper explanations for the artifacts shortlisted. EXPLAIN IN WHICH PART OF THE IMAGE THE ARTIFACT IS EXHIBITED.\n",
    "Omit the artifact if it is not applicable to the image. Explain strictly in context of the given image.\n",
    "\n",
    "artifacts:- \n",
    "Metallic surface artifacts \n",
    "Distorted window reflections\n",
    "Unrealistic specular highlights\n",
    "Inconsistent shadow directions\n",
    "Multiple light source conflicts\n",
    "Missing ambient occlusion\n",
    "Incorrect reflection mapping\n",
    "Unnaturally glossy surfaces\n",
    "Unnatural Lighting Gradients\n",
    "Unnatural color transitions\n",
    "Multiple inconsistent shadow sources\n",
    "Glow or light bleed around object boundaries\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Over_Processing = \"\"\"\n",
    "TASK: For the provided artifacts, Shortlist the artifacts which are applicable to the given image. \n",
    "Generate proper explanations for the artifacts shortlisted. EXPLAIN IN WHICH PART OF THE IMAGE THE ARTIFACT IS EXHIBITED.\n",
    "Omit the artifact if it is not applicable to the image. Explain strictly in context of the given image.\n",
    "\n",
    "artifacts:- \n",
    "Regular grid-like artifacts in textures\n",
    "Movie-poster like composition of ordinary scenes\n",
    "Cinematization Effects\n",
    "Excessive sharpness in certain image regions\n",
    "Dramatic lighting that defies natural physics\n",
    "Exaggerated characteristic features\n",
    "Scale inconsistencies within the same object class\n",
    "Frequency domain signatures\n",
    "Over-sharpening artifacts\n",
    "Artificial smoothness\n",
    "Over-smoothing of natural textures \n",
    "Scale inconsistencies within single objects\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_text = \"\"\"\n",
    "- Inconsistent object boundaries\n",
    "- Discontinuous surfaces\n",
    "- Non-manifold geometries in rigid structures\n",
    "- Floating or disconnected components\n",
    "- Asymmetric features in naturally symmetric objects \n",
    "- Misaligned bilateral elements in animal faces \n",
    "- Irregular proportions in mechanical components \n",
    "- Texture bleeding between adjacent regions\n",
    "- Texture repetition patterns\n",
    "- Over-smoothing of natural textures \n",
    "- Artificial noise patterns in uniform surfaces\n",
    "- Unrealistic specular highlights\n",
    "- Inconsistent material properties\n",
    "- Metallic surface artifacts \n",
    "- Dental anomalies in mammals \n",
    "- Anatomically incorrect paw structures\n",
    "- Improper fur direction flows\n",
    "- Unrealistic eye reflections\n",
    "- Misshapen ears or appendages\n",
    "- Impossible mechanical connections\n",
    "- Inconsistent scale of mechanical parts\n",
    "- Physically impossible structural elements\n",
    "- Inconsistent shadow directions\n",
    "- Multiple light source conflicts\n",
    "- Missing ambient occlusion\n",
    "- Incorrect reflection mapping\n",
    "- Incorrect perspective rendering\n",
    "- Scale inconsistencies within single objects\n",
    "- Spatial relationship errors\n",
    "- Depth perception anomalies\n",
    "- Over-sharpening artifacts\n",
    "- Aliasing along high-contrast edges\n",
    "- Blurred boundaries in fine details\n",
    "- Jagged edges in curved structures\n",
    "- Random noise patterns in detailed areas\n",
    "- Loss of fine detail in complex structures\n",
    "- Artificial enhancement artifacts\n",
    "- Incorrect wheel geometry\n",
    "- Implausible aerodynamic structures\n",
    "- Misaligned body panels\n",
    "- Impossible mechanical joints\n",
    "- Distorted window reflections\n",
    "- Anatomically impossible joint configurations\n",
    "- Unnatural pose artifacts\n",
    "- Biological asymmetry errors\n",
    "- Regular grid-like artifacts in textures\n",
    "- Repeated element patterns\n",
    "- Systematic color distribution anomalies\n",
    "- Frequency domain signatures\n",
    "- Color coherence breaks\n",
    "- Unnatural color transitions\n",
    "- Resolution inconsistencies within regions\n",
    "- Unnatural Lighting Gradients\n",
    "- Incorrect Skin Tones\n",
    "- Fake depth of field\n",
    "- Abruptly cut off objects\n",
    "- Glow or light bleed around object boundaries\n",
    "- Ghosting effects: Semi-transparent duplicates of elements\n",
    "- Cinematization Effects\n",
    "- Excessive sharpness in certain image regions\n",
    "- Artificial smoothness\n",
    "- Movie-poster like composition of ordinary scenes\n",
    "- Dramatic lighting that defies natural physics\n",
    "- Artificial depth of field in object presentation\n",
    "- Unnaturally glossy surfaces\n",
    "- Synthetic material appearance\n",
    "- Multiple inconsistent shadow sources\n",
    "- Exaggerated characteristic features\n",
    "- Impossible foreshortening in animal bodies\n",
    "- Scale inconsistencies within the same object class\n",
    "\"\"\"\n",
    "\n",
    "artifacts_list = [line.strip(\"- \").strip() for line in artifacts_text.strip().split(\"\\n\") if line.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_and_prompt(model, processor, image_path, prompt, max_tokens=1024):\n",
    "    # Load and display the image\n",
    "    if image_path.startswith('http'):\n",
    "        image = Image.open(requests.get(image_path, stream=True).raw)\n",
    "    else:\n",
    "        image = Image.open(image_path)\n",
    "    \n",
    "    # Prepare messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\" : [\n",
    "                {\"type\": \"text\", \"text\": \"You are an expert in identifying and analyzing artifacts that indicate why the image may appear unnatural or fake\"}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": image},\n",
    "                {\"type\": \"text\", \"text\": prompt}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Process input\n",
    "    input_text = processor.apply_chat_template(messages, tokenize = False, add_generation_prompt=True)\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text = input_text,\n",
    "        images = image_inputs,\n",
    "        videos = video_inputs,\n",
    "        padding = True,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "    \n",
    "    # Generate output\n",
    "    with torch.inference_mode():\n",
    "        output = model.generate(**inputs, temperature = 0.1, max_new_tokens=max_tokens)\n",
    "    \n",
    "    # Decode output\n",
    "        generated_ids_trimmed = [\n",
    "            out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, output)\n",
    "        ]\n",
    "        response = processor.batch_decode(\n",
    "            generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )\n",
    "    \n",
    "    # Clean up memory\n",
    "    del inputs, output\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_artifacts(text):\n",
    "    # Initialize dictionary to store results\n",
    "    artifacts = {}\n",
    "    \n",
    "    # Split text into lines and process\n",
    "    current_category = None\n",
    "    \n",
    "    for line in text.strip().split('\\n'):\n",
    "        if ':' in line:\n",
    "            # Get category and items\n",
    "            category, items = line.split(':')\n",
    "            items = items.strip()\n",
    "            \n",
    "            # If items is not \"None\", split them and add to dictionary\n",
    "            if items.lower() != \"none\":\n",
    "                # Split items by comma and clean up each item\n",
    "                item_list = [item.strip() for item in items.split(',')]\n",
    "                artifacts[category] = item_list\n",
    "                \n",
    "    return artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_outputs(model, processor, response, max_tokens=1024):\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"\n",
    "            You are an assistant that refines explanations of potential artifacts in images. \n",
    "            The explanations are given in a structured format, and your job is to analyse each explanation parse them in json format.\n",
    "                \n",
    "        \"\"\"}, \n",
    "        {\"role\": \"user\", \"content\": response}\n",
    "    ]\n",
    "\n",
    "    input_text = processor.apply_chat_template(messages, tokenize = False, add_generation_prompt=True)\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text = input_text,\n",
    "        images = image_inputs,\n",
    "        videos = video_inputs,\n",
    "        padding = True,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "    \n",
    "    # Generate output\n",
    "    with torch.inference_mode():\n",
    "        output = model.generate(**inputs, temperature = 0.1, max_new_tokens=max_tokens)\n",
    "    \n",
    "    # Decode output\n",
    "        generated_ids_trimmed = [\n",
    "            out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, output)\n",
    "        ]\n",
    "        json_response = processor.batch_decode(\n",
    "            generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )\n",
    "    \n",
    "    # Clean up memory\n",
    "    del inputs, output\n",
    "\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(imagelink):\n",
    "    # Start timing\n",
    "    start = time.time()\n",
    "    \n",
    "    # Display the image\n",
    "    img = Image.open(imagelink)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Input Image')\n",
    "    plt.show()\n",
    "\n",
    "    categories = {\n",
    "        \"AI Defects\" : AI_defects,\n",
    "        \"Biological Defects\" : Biological_issues,\n",
    "        \"Overprocessing\" : Over_Processing,\n",
    "        \"Scene Oddities\" : Scene_oddities,\n",
    "        \"Reality Breaks\" : Reality_breaks,\n",
    "        \"Texture Defects\": Surface_Depth_Edge_Problems\n",
    "    }\n",
    "\n",
    "    classification_response = process_image_and_prompt(model, processor, imagelink, classification_prompt, 142)[0]\n",
    "\n",
    "    artifacts = extract_artifacts(classification_response)\n",
    "    group_responses = {}\n",
    "    json_responses = []\n",
    "\n",
    "    possible_keys = [\n",
    "    \"AI Defects\",\n",
    "    \"Biological Defects\",\n",
    "    \"Overprocessing\",\n",
    "    \"Scene Oddities\",\n",
    "    \"Reality Breaks\",\n",
    "    \"Texture Defects\"]\n",
    "        \n",
    "    for key, values in artifacts.items():\n",
    "        if key not in possible_keys:\n",
    "            continue\n",
    "\n",
    "        a1 = time.time()\n",
    "        \n",
    "        problems = \"\"\n",
    "        for value in values:\n",
    "            problems += value + \", \" \n",
    "        prompt = f\"\"\" The image is detected to have the following problems: \\n {problems}\n",
    "\n",
    "        {categories[key]}\n",
    "        \"\"\"\n",
    "        group_response = process_image_and_prompt(model, processor, imagelink, prompt)[0]\n",
    "        group_responses[key] = group_response\n",
    "        \n",
    "        json_response = get_json_outputs(model, processor, group_response)\n",
    "        json_responses.append(json_response)\n",
    "\n",
    "        \n",
    "    # Print total processing time\n",
    "\n",
    "    return classification_response, group_responses, json_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_response, group_responses, json_responses = classify_image(\"/kaggle/input/testdataadobe/perturbed_images_32/67.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/kaggle/input/testdataadobe/perturbed_images_32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "\n",
    "start = 1\n",
    "end = 301\n",
    "for i in range(start, end):\n",
    "    image_paths.append(image_dir + \"/\" + str(i) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classifications = {}\n",
    "all_explanations = {}\n",
    "all_jsons = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in tqdm(image_paths):\n",
    "    classification_response, group_responses, json_responses = classify_image(path)\n",
    "    all_classification[path] = classification_response\n",
    "    all_explanations[path] = group_responses\n",
    "    all_jsons[path] = json_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Define filenames for each dictionary\n",
    "classification_file = \"all_classification.pkl\"\n",
    "explanations_file = \"all_explanations.pkl\"\n",
    "jsons_file = \"all_jsons.pkl\"\n",
    "\n",
    "# Save each dictionary as a pickle file\n",
    "with open(classification_file, \"wb\") as f:\n",
    "    pickle.dump(all_classification, f)\n",
    "\n",
    "with open(explanations_file, \"wb\") as f:\n",
    "    pickle.dump(all_explanations, f)\n",
    "\n",
    "with open(jsons_file, \"wb\") as f:\n",
    "    pickle.dump(all_jsons, f)\n",
    "\n",
    "print(\"Files saved successfully:\")\n",
    "print(f\"- {classification_file}\")\n",
    "print(f\"- {explanations_file}\")\n",
    "print(f\"- {jsons_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3041726,
     "sourceId": 5256696,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6233623,
     "sourceId": 10105691,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
