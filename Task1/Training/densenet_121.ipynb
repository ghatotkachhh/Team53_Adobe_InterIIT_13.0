{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5256696,"sourceType":"datasetVersion","datasetId":3041726},{"sourceId":7456613,"sourceType":"datasetVersion","datasetId":4340359},{"sourceId":9989735,"sourceType":"datasetVersion","datasetId":6147944},{"sourceId":175378,"sourceType":"modelInstanceVersion","modelInstanceId":149321,"modelId":171825}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Prerequisites\n\nFirst of all, we import all of the modules, functions, and classes that we are\ngoing to use.\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport sys\nimport torch\nimport torchvision\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport torchvision.models as models\nfrom contextlib import nullcontext\nfrom functools import partialmethod\nfrom pprint import pp\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom torch import optim\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data.dataloader import DataLoader\nimport os\nimport random\nimport torchvision.transforms as T\nfrom torch.utils.data import Dataset\nfrom PIL import Image, ImageFilter\nimport numpy as np\nimport cv2\nimport io\nfrom typing import Optional\nfrom torch.optim import AdamW\nplt.rcParams[\"font.family\"] = \"serif\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T10:24:07.006307Z","iopub.execute_input":"2024-12-06T10:24:07.007088Z","iopub.status.idle":"2024-12-06T10:24:07.013512Z","shell.execute_reply.started":"2024-12-06T10:24:07.007052Z","shell.execute_reply":"2024-12-06T10:24:07.012549Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Here, we set the seed for PyTorch's RNG to get (not entirely) reproducible\nresults.\n","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(512)\n\nprint(f\"Set {512} as the seed of Torch's RNG!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T10:24:07.024545Z","iopub.execute_input":"2024-12-06T10:24:07.024833Z","iopub.status.idle":"2024-12-06T10:24:07.031967Z","shell.execute_reply.started":"2024-12-06T10:24:07.024805Z","shell.execute_reply":"2024-12-06T10:24:07.031143Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"And as the final part in this section, we load the CUDA device in case it is\navailable.\n","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(f\"Using {device} device!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T10:24:07.033521Z","iopub.execute_input":"2024-12-06T10:24:07.033750Z","iopub.status.idle":"2024-12-06T10:24:07.042981Z","shell.execute_reply.started":"2024-12-06T10:24:07.033720Z","shell.execute_reply":"2024-12-06T10:24:07.042155Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data\n","metadata":{}},{"cell_type":"markdown","source":"## Loading\n\nFirst, we need to load the data from the directory in which the dataset is\nstored.\n\nBy default, PyTorch sorts the labels and sets the target values according to it.\nIn this case, 0 is assigned to the label FAKE and 1 is assigned to the label\nREAL. But, we prefer to have 1 for FAKE and 0 for REAL since it's more logical\nto have the error signal, 1, to indicate a fake image. Thus, we define the\nfollowing class to handle this transformation.\n","metadata":{}},{"cell_type":"code","source":"class TargetMapper:\n    def __init__(self, labels):\n        self.labels_dict = {v: k for k, v in enumerate(labels)}\n        self.labels_list = sorted(labels)\n\n    def __call__(self, target):\n        return self.labels_dict[self.labels_list[target]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T10:24:07.044020Z","iopub.execute_input":"2024-12-06T10:24:07.044484Z","iopub.status.idle":"2024-12-06T10:24:07.056869Z","shell.execute_reply.started":"2024-12-06T10:24:07.044441Z","shell.execute_reply":"2024-12-06T10:24:07.056225Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Path","metadata":{}},{"cell_type":"code","source":"# Paths\nartifact_path = \"/kaggle/input/artifacts-cleaned/ArtiFact\"\ngenimage_path = \"/kaggle/input/tiny-genimage\"\ncifake_path = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T10:24:07.058329Z","iopub.execute_input":"2024-12-06T10:24:07.059323Z","iopub.status.idle":"2024-12-06T10:24:07.068904Z","shell.execute_reply.started":"2024-12-06T10:24:07.059256Z","shell.execute_reply":"2024-12-06T10:24:07.067830Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Augmentations","metadata":{}},{"cell_type":"code","source":"\n# Augmentation Classes\nclass JPEGCompression:\n    def __init__(self, quality_range=(30, 100), p=0.5, use_pil_jpeg=True):\n        self.quality_range = quality_range\n        self.p = p\n        self.use_pil_jpeg = use_pil_jpeg\n\n    def __call__(self, img):\n        if random.random() > self.p:\n            return img\n\n        quality = random.randint(self.quality_range[0], self.quality_range[1])\n\n        if self.use_pil_jpeg:\n            # PIL JPEG compression\n            buffer = io.BytesIO()\n            img.save(buffer, format='JPEG', quality=quality)\n            buffer.seek(0)\n            img = Image.open(buffer)\n        else:\n            # OpenCV JPEG compression\n            img_np = np.array(img)\n            encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), quality]\n            _, encoded_img = cv2.imencode('.jpg', cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR), encode_param)\n            decoded_img = cv2.imdecode(encoded_img, cv2.IMREAD_COLOR)\n            img = Image.fromarray(cv2.cvtColor(decoded_img, cv2.COLOR_BGR2RGB))\n\n        return img\n\n\nclass RandomGaussianBlur:\n    def __init__(self, sigma_range=(0, 3), p=0.5):\n        self.sigma_range = sigma_range\n        self.p = p\n\n    def __call__(self, img):\n        if random.random() > self.p:\n            return img\n\n        sigma = random.uniform(self.sigma_range[0], self.sigma_range[1])\n        return img.filter(ImageFilter.GaussianBlur(radius=sigma))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T10:24:07.075300Z","iopub.execute_input":"2024-12-06T10:24:07.076135Z","iopub.status.idle":"2024-12-06T10:24:07.083730Z","shell.execute_reply.started":"2024-12-06T10:24:07.076077Z","shell.execute_reply":"2024-12-06T10:24:07.083014Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset Class","metadata":{}},{"cell_type":"code","source":"\n\n# Dataset Class\nclass RandomizedDataset(Dataset):\n    def __init__(self, data_paths, transform=None, sample_fraction=1.0):\n        self.data = []\n        self.labels = []\n        self.transform = transform\n\n        # Load data\n        for root_path, label_map in data_paths:\n            for label_name, label_value in label_map.items():\n                folder_path = os.path.join(root_path, label_name)\n                if os.path.exists(folder_path):\n                    images = [\n                        os.path.join(folder_path, filename)\n                        for filename in os.listdir(folder_path)\n                        if filename.endswith((\".png\", \".jpg\", \".jpeg\"))\n                    ]\n                    labels = [label_value] * len(images)\n                    self.data.extend(images)\n                    self.labels.extend(labels)\n\n        # Apply random sampling if sample_fraction < 1.0\n        if sample_fraction < 1.0:\n            sampled_indices = random.sample(range(len(self.data)), int(sample_fraction * len(self.data)))\n            self.data = [self.data[i] for i in sampled_indices]\n            self.labels = [self.labels[i] for i in sampled_indices]\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image_path = self.data[idx]\n        label = self.labels[idx]\n\n        img = Image.open(image_path).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img, label\n\n\n\n# Helper function to prepare label mappings\ndef prepare_genimage_paths(root_path):\n    data_paths = []\n    subdirectories = [os.path.join(root_path, subdir) for subdir in os.listdir(root_path) if os.path.isdir(os.path.join(root_path, subdir))]\n\n    for subdir in subdirectories:\n        train_path = os.path.join(subdir, \"train\")\n        val_path = os.path.join(subdir, \"val\")\n\n        if os.path.exists(train_path):\n            data_paths.append((train_path, {\"ai\": 1, \"nature\": 0}))\n\n        if os.path.exists(val_path):\n            data_paths.append((val_path, {\"ai\": 1, \"nature\": 0}))\n\n    return data_paths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T10:24:07.126709Z","iopub.execute_input":"2024-12-06T10:24:07.127265Z","iopub.status.idle":"2024-12-06T10:24:07.144464Z","shell.execute_reply.started":"2024-12-06T10:24:07.127236Z","shell.execute_reply":"2024-12-06T10:24:07.143557Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transformation Class","metadata":{}},{"cell_type":"code","source":"\n\n# Prepare transformations\ndef get_transforms(augmentation_type: str = \"blur+jpeg_0.5\") -> tuple:\n    base_transform = [\n        T.Resize((32,32)),\n        T.RandomHorizontalFlip(),\n        T.ToTensor(),\n        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ]\n\n    test_transform = T.Compose([\n        T.Resize((32,32)),\n        T.ToTensor(),\n        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n\n    if augmentation_type == \"no_aug\":\n        train_transform = base_transform\n\n    elif augmentation_type == \"gaussian_blur\":\n        train_transform = [RandomGaussianBlur(p=0.5)] + base_transform\n\n    elif augmentation_type == \"jpeg\":\n        train_transform = [JPEGCompression(p=0.5, use_pil_jpeg=random.choice([True, False]))] + base_transform\n\n    elif augmentation_type == \"blur+jpeg_0.5\":\n        train_transform = [\n            RandomGaussianBlur(p=0.2),\n            JPEGCompression(p=0.2, use_pil_jpeg=random.choice([True, False])),\n        ] + base_transform\n\n    elif augmentation_type == \"blur+jpeg_0.1\":\n        train_transform = [\n            RandomGaussianBlur(p=0.1),\n            JPEGCompression(p=0.1, use_pil_jpeg=random.choice([True, False])),\n        ] + base_transform\n\n    else:\n        raise ValueError(f\"Unknown augmentation type: {augmentation_type}\")\n\n    return T.Compose(train_transform), test_transform\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T10:24:07.146169Z","iopub.execute_input":"2024-12-06T10:24:07.146434Z","iopub.status.idle":"2024-12-06T10:24:07.159766Z","shell.execute_reply.started":"2024-12-06T10:24:07.146411Z","shell.execute_reply":"2024-12-06T10:24:07.158806Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train and Val Loader","metadata":{}},{"cell_type":"code","source":"# Prepare datasets\ntrain_data_paths = [\n    (os.path.join(artifact_path, \"train\"), {\"FAKE\": 1, \"REAL\": 0}),\n    (os.path.join(cifake_path, \"train\"), {\"FAKE\": 1, \"REAL\": 0}),\n]\ntrain_data_paths.extend(prepare_genimage_paths(genimage_path))\n\nval_data_paths = [\n    (os.path.join(artifact_path, \"val\"), {\"FAKE\": 1, \"REAL\": 0}),\n    (os.path.join(cifake_path, \"test\"), {\"FAKE\": 1, \"REAL\": 0}),\n]\nval_data_paths.extend(prepare_genimage_paths(genimage_path))\n\n# Get transforms\ntrain_transform, test_transform = get_transforms(augmentation_type=\"no_aug\")\n\n# Create datasets\ntrain_data = RandomizedDataset(train_data_paths, transform=train_transform, sample_fraction=0.8)\nval_data = RandomizedDataset(val_data_paths, transform=test_transform)\n\n# DataLoaders\ndef collate_fn(batch):\n    images, labels = zip(*batch)\n    images = torch.stack(images).to(device)\n    labels = torch.tensor(labels).to(device)\n    return images, labels\n\ntrain_loader = DataLoader(train_data, batch_size=128, shuffle=True, collate_fn=collate_fn)\nval_loader = DataLoader(val_data, batch_size=128, shuffle=False, collate_fn=collate_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T10:24:07.160757Z","iopub.execute_input":"2024-12-06T10:24:07.161073Z","iopub.status.idle":"2024-12-06T10:24:07.888280Z","shell.execute_reply.started":"2024-12-06T10:24:07.161038Z","shell.execute_reply":"2024-12-06T10:24:07.887560Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Utilities\n\nHere, we define the following class to stop the training process if no\nimprovements are gained. It also handles saving and reloading the best model\nparameters.\n","metadata":{}},{"cell_type":"code","source":"class EarlyStopping():\n    def __init__(self, model, patience=5, metric_name=\"loss\", mode=\"min\", device=\"cuda\"):\n        \"\"\"\n        Early stopping utility for PyTorch models.\n\n        Args:\n        - model: The PyTorch model to monitor and save.\n        - patience: Number of epochs with no improvement after which training will stop.\n        - metric_name: The name of the metric to monitor.\n        - mode: \"min\" for minimizing the metric, \"max\" for maximizing the metric.\n        - device: The device on which the operations should run (\"cuda\" or \"cpu\").\n        \"\"\"\n        self.model = model\n        self.patience = patience\n        self.metric_name = metric_name\n        self.mode = mode\n        self.device = device\n        self.counter = 0\n        self.best_metric_value = float(\"inf\") if mode == \"min\" else -float(\"inf\")\n        self.checkpoint_path = \"_checkpoint.pth\"\n\n    def __call__(self, metrics, last_epoch=False):\n        \"\"\"\n        Checks whether training should stop based on the monitored metric.\n\n        Args:\n        - metrics: A dictionary containing the monitored metrics.\n        - last_epoch: Boolean indicating if this is the final epoch.\n\n        Returns:\n        - should_stop: Boolean indicating whether training should stop.\n        \"\"\"\n        metric_value = metrics[self.metric_name]\n        delta = metric_value - self.best_metric_value\n        improvement = delta > 0 if self.mode == \"max\" else delta < 0\n\n        if improvement:\n            self.counter = 0\n            self.best_metric_value = metric_value\n            self._save_checkpoint()\n        else:\n            self.counter += 1\n\n        should_stop = self.counter >= self.patience\n\n        if should_stop or last_epoch:\n            self._load_checkpoint()\n\n        return should_stop\n\n    def _save_checkpoint(self):\n        \"\"\"Saves the model state to a checkpoint file.\"\"\"\n        torch.save(self.model.state_dict(), self.checkpoint_path)\n\n    def _load_checkpoint(self):\n        \"\"\"Loads the model state from the checkpoint file.\"\"\"\n        self.model.load_state_dict(torch.load(self.checkpoint_path, map_location=self.device))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T10:24:07.890002Z","iopub.execute_input":"2024-12-06T10:24:07.890306Z","iopub.status.idle":"2024-12-06T10:24:07.897650Z","shell.execute_reply.started":"2024-12-06T10:24:07.890281Z","shell.execute_reply":"2024-12-06T10:24:07.896740Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training Loop","metadata":{}},{"cell_type":"code","source":"\nEPOCHS = 10\nVERBOSE = False\n\ndef file_name(model, suffix=\"\"):\n    return f\"{OUTPUT_DIR}/{model.name}{suffix}.pt\"\ndef update_history(history, metrics):\n    \"\"\"\n    Updates the training history with metrics from the current epoch.\n\n    Args:\n    - history (dict): The dictionary storing the history of metrics.\n    - metrics (dict): The current epoch's metrics containing \"train\" and \"val\" keys.\n    \"\"\"\n    # Initialize keys in history if empty\n    if not history:\n        for split in metrics:\n            history[split] = {key: [] for key in metrics[split].keys()}\n\n    # Append metrics to history\n    for split in metrics:\n        for key, value in metrics[split].items():\n            history[split][key].append(value)\n\ndef save_model(model, optimizer, suffix=\"\"):\n    torch.save(\n        {\n            \"model\": model.state_dict(),\n            \"optimizer\": optimizer.state_dict(),\n        },\n        file_name(model, suffix),\n    )\n\ndef load_model(model, optimizer, suffix=\"\"):\n    checkpoint = torch.load(file_name(model, suffix), map_location=device)\n    model.load_state_dict(checkpoint[\"model\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n\ndef get_metrics(model, optimizer, loader, split, desc_prefix=\"\"):\n    with torch.no_grad() if split == \"val\" else nullcontext():\n        model.train() if split == \"train\" else model.eval()\n\n        desc = f\"{desc_prefix}{split.title()}ing\"\n        total_loss, total_items = 0.0, 0\n        tp, tn, fp, fn = 0, 0, 0, 0\n\n        for images, labels in (\n            tqdm(loader, desc=desc, file=sys.stdout) if VERBOSE else loader\n        ):\n            # Move data to GPU\n            images = images.to(device)\n            labels = labels.to(device).unsqueeze(1)\n            items = images.shape[0]\n\n            if split == \"train\":\n                optimizer.zero_grad()\n\n            # Forward pass\n            outputs = model(images)\n            predictions = (outputs >= 0.5).float()\n            loss = model.loss_function(outputs, labels.float())\n\n            if split == \"train\":\n                # Backward pass and optimizer step\n                loss.backward()\n                optimizer.step()\n\n            # Accumulate metrics\n            total_loss += loss.item() * items\n            total_items += items\n\n            tp += ((predictions == 1) & (labels == 1)).sum().item()\n            tn += ((predictions == 0) & (labels == 0)).sum().item()\n            fp += ((predictions == 1) & (labels == 0)).sum().item()\n            fn += ((predictions == 0) & (labels == 1)).sum().item()\n\n        # Calculate overall metrics\n        loss = total_loss / total_items\n        accuracy = (tp + tn) / (tp + tn + fp + fn)\n        precision = tp / (tp + fp) if tp + fp > 0 else 0.0\n        recall = tp / (tp + fn) if tp + fn > 0 else 0.0\n        f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0.0\n\n        # Create confusion matrix\n        confusion_matrix = torch.tensor(\n            [\n                [tn, fp],\n                [fn, tp],\n            ]\n        ).cpu().numpy()  # Move to CPU for compatibility with numpy\n\n        return {\n            \"loss\": loss,\n            \"accuracy\": accuracy,\n            \"precision\": precision,\n            \"recall\": recall,\n            \"f1_score\": f1_score,\n            \"confusion_matrix\": confusion_matrix,\n        }\n\n\ndef train_model(model, optimizer, train_loader, val_loader):\n    # Move model to GPU\n    model.to(device)\n\n    early_stopping = EarlyStopping(model)\n    history = {}\n\n    for epoch in range(EPOCHS):\n        print(f\"Epoch {epoch + 1}/{EPOCHS}{':' if VERBOSE else '...'}\")\n\n        # Add tqdm progress bar for the training loop\n        train_loader_tqdm = tqdm(train_loader, desc=\"Training\", leave=False)\n        val_loader_tqdm = tqdm(val_loader, desc=\"Validation\", leave=False)\n\n        # Get metrics for training\n        train_metrics = get_metrics(model, optimizer, train_loader_tqdm, split=\"train\", desc_prefix=\"Epoch \")\n\n        # Get metrics for validation\n        val_metrics = get_metrics(model, optimizer, val_loader_tqdm, split=\"val\", desc_prefix=\"Epoch \")\n\n        # Combine metrics\n        metrics = {\"train\": train_metrics, \"val\": val_metrics}\n\n        # Update training history\n        update_history(history, metrics)\n\n        # Print metrics for the epoch\n        print(f\"Epoch {epoch + 1} Results:\")\n        print(f\"  Train Loss: {train_metrics['loss']:.4f}, Accuracy: {train_metrics['accuracy']:.4f}, \"\n              f\"Precision: {train_metrics['precision']:.4f}, Recall: {train_metrics['recall']:.4f}, \"\n              f\"F1-Score: {train_metrics['f1_score']:.4f}\")\n        print(f\"  Val Loss:   {val_metrics['loss']:.4f}, Accuracy: {val_metrics['accuracy']:.4f}, \"\n              f\"Precision: {val_metrics['precision']:.4f}, Recall: {val_metrics['recall']:.4f}, \"\n              f\"F1-Score: {val_metrics['f1_score']:.4f}\")\n\n        if VERBOSE:\n            print_results(metrics)\n\n        # Early stopping based on validation metrics\n        if early_stopping(metrics[\"val\"], last_epoch=epoch == (EPOCHS - 1)):\n            break\n\n    # Final evaluation on validation set\n    return get_metrics(model, optimizer, val_loader, split=\"val\"), history\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T10:24:07.898837Z","iopub.execute_input":"2024-12-06T10:24:07.899295Z","iopub.status.idle":"2024-12-06T10:24:07.921575Z","shell.execute_reply.started":"2024-12-06T10:24:07.899259Z","shell.execute_reply":"2024-12-06T10:24:07.920814Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This is the base for our CNN models.\n","metadata":{}},{"cell_type":"markdown","source":"## Original Model\n\nThe CIFAKE paper evaluates several models. This model is one of them and was\nrecommended by the authors.\n","metadata":{}},{"cell_type":"code","source":"class CifakeNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.name = \"cifakenet\"\n\n        # Load the DenseNet-121 model\n        densenet = models.densenet121(pretrained=True)\n        self.features = densenet.features\n\n        # Define the MLP head for classification\n        self.mlp_head = nn.Sequential(\n            nn.Linear(densenet.classifier.in_features, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1),\n            nn.Sigmoid(),\n        )\n\n        # Loss function\n        self.loss_function = nn.BCELoss()\n\n    def forward(self, x):\n        # Forward pass through feature extractor\n        x = self.features(x)\n        x = torch.flatten(x, 1)  # Flatten the output\n\n        # Forward pass through the MLP head\n        x = self.mlp_head(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-12-06T10:24:07.922686Z","iopub.execute_input":"2024-12-06T10:24:07.923194Z","iopub.status.idle":"2024-12-06T10:24:07.934984Z","shell.execute_reply.started":"2024-12-06T10:24:07.923166Z","shell.execute_reply":"2024-12-06T10:24:07.934357Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In the following cells, we initialize the model and run the routine on it. The\nroutine includes training, evaluating, and drawing the evaluation results plus\nthe actiavation maps.\n","metadata":{}},{"cell_type":"code","source":"model = CifakeNet()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T10:24:07.935893Z","iopub.execute_input":"2024-12-06T10:24:07.936171Z","iopub.status.idle":"2024-12-06T10:24:08.658360Z","shell.execute_reply.started":"2024-12-06T10:24:07.936136Z","shell.execute_reply":"2024-12-06T10:24:08.657481Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T10:24:08.659443Z","iopub.execute_input":"2024-12-06T10:24:08.659711Z","iopub.status.idle":"2024-12-06T10:24:08.842370Z","shell.execute_reply.started":"2024-12-06T10:24:08.659686Z","shell.execute_reply":"2024-12-06T10:24:08.841408Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T10:24:08.844928Z","iopub.execute_input":"2024-12-06T10:24:08.845244Z","iopub.status.idle":"2024-12-06T10:24:08.850961Z","shell.execute_reply.started":"2024-12-06T10:24:08.845217Z","shell.execute_reply":"2024-12-06T10:24:08.850080Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"saved_model = torch.load(\"/kaggle/input/densenet_cifake/pytorch/default/1/cifakenet.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T10:24:08.851872Z","iopub.execute_input":"2024-12-06T10:24:08.852250Z","iopub.status.idle":"2024-12-06T10:24:10.777817Z","shell.execute_reply.started":"2024-12-06T10:24:08.852214Z","shell.execute_reply":"2024-12-06T10:24:10.776859Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_metrics, history = train_model(model, optimizer, train_loader, val_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T10:24:10.778915Z","iopub.execute_input":"2024-12-06T10:24:10.779223Z","iopub.status.idle":"2024-12-06T10:57:13.823852Z","shell.execute_reply.started":"2024-12-06T10:24:10.779190Z","shell.execute_reply":"2024-12-06T10:57:13.822443Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_save_path = \"/kaggle/working/densenet121\"\n\n# Save the model\ntorch.save(model.state_dict(), model_save_path)\n\nprint(f\"Model saved to {model_save_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T10:57:13.824938Z","iopub.status.idle":"2024-12-06T10:57:13.825412Z","shell.execute_reply.started":"2024-12-06T10:57:13.825175Z","shell.execute_reply":"2024-12-06T10:57:13.825198Z"}},"outputs":[],"execution_count":null}]}